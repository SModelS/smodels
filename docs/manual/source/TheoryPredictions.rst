.. index:: Theory Predictions

.. |EM| replace:: :ref:`EM-type <EMtype>`
.. |UL| replace:: :ref:`UL-type <ULtype>`
.. |EMr| replace:: :ref:`EM-type result <EMtype>`
.. |ULr| replace:: :ref:`UL-type result <ULtype>`
.. |EMrs| replace:: :ref:`EM-type results <EMtype>`
.. |ULrs| replace:: :ref:`UL-type results <ULtype>`
.. |ExpRes| replace:: :ref:`Experimental Result<ExpResult>`
.. |ExpRess| replace:: :ref:`Experimental Results<ExpResult>`
.. |database| replace:: :ref:`database <databaseDefs>`
.. |Database| replace:: :ref:`Database <databaseDefs>`   
.. |Dataset| replace:: :ref:`DataSet<DataSet>`
.. |Datasets| replace:: :ref:`DataSets<DataSet>`
.. |dataset| replace:: :ref:`data set<DataSet>`
.. |datasets| replace:: :ref:`data sets<DataSet>`
.. |particle| replace:: :ref:`particle <particleClass>`
.. |particles| replace:: :ref:`particles <particleClass>`
.. |SMS| replace:: :ref:`SMS <SMS>`
.. |SMS topology| replace:: :ref:`SMS topology <SMS>`
.. |SMS topologies| replace:: :ref:`SMS topologies <SMS>`
.. |topology| replace:: :ref:`topology <SMS>`   
.. |topologies| replace:: :ref:`topologies <SMS>`
.. |decomposition| replace:: :ref:`decomposition <decomposition>`
.. |sigBR| replace:: :math:`\sigma \times BR`
.. |sigBRe| replace:: :math:`\sigma \times BR \times \epsilon`
.. |ssigBRe| replace:: :math:`\sum \sigma \times BR \times \epsilon`
.. |canonical name| replace:: :ref:`canonical name <canonicalName>`
.. |canonical names| replace:: :ref:`canonical names <canonicalName>`

.. _theoryPredictions:

SMS Matching and Theory Predictions
================================

The |decomposition| of the input model as a sum of |SMS|
(simplified models) is the
first step for confronting the model with the experimental limits.
The next step consists of *matching* the |SMS| from the decomposition to the |topologies| constrained by the database and computing the relevant signal cross sections
(or *theory predictions*) for comparison with the experimental limits. :numref:`Fig. %s <tpA>` schematically shows these two steps.

.. _tpA:

.. figure:: images/theoryPredA.png
   :width: 50%
   :align: center

   Schematic representation of the matching between |SMS topologies| generated by the |decomposition| and the |topologies| found in the database as well as the calculation of the relevant theory predictions and the comparison with the corresponding upper limits.

Below we describe in detail the procedure
for matching the |SMS topologies| and for computing the theory predictions.


Matching SMS Topologies
-----------------------

Once the |SMS topologies| (here called *model topologies*) representing the input BSM model are created by the |decomposition|, they have to be matched to the |topologies| constrained by the |Database| (*database topologies*).
Two topologies will match if they have the same structure and the corresponding particles appearing in each topology have matching properties (electric charge, color representation, spin,...).\ [#f3]_


Two |SMS| match if their the root nodes (primary vertices) match.Any two nodes will be considered matched if:

  1. their :ref:`canonical names <canonicalName>` are equal,
  2. their |particle| attributes match and
  3. their daughter nodes match *irrespective* of their ordering

With these criteria, the |SMS topologies| are traversed following a depth-first search until all nodes have been matched (if possible). In order to illustrate this procedure it is useful to consider the example of the model and database topologies shown in :numref:`Fig. %s <matchA>`.

.. _matchA:

.. figure:: images/theoryPredB.png
   :width: 40%
   :align: center

   Example of two topologies to be matched and the respective |canonical names| for their nodes.

The procedure compares the root nodes, which in this example have the same canonical names (this enforces that both |SMS| have the same structure) and the same particle properties (which is always assumed as true to root nodes). This is indicated by *Step 0* in :numref:`Fig. %s <matchB>`.
Hence criteria 1. and 2. for matching two nodes are satisfied. 


The next step consists in comparing the root nodes daughters *irrespective of their order*. In this example these are (gluino, N1) from the model topology and (MET,anyBSM) from the database topology, as shown by. Once again we compare their canonical names and particle properties (*Step B* in :numref:`Fig. %s <matchB>`).
Note that although the particle properties of N1 and anyBSM match, their canonical names are different, hence we only have the following partial matches:

 * gluino :math:`\leftrightarrow` anyBSM
 * N1 :math:`\leftrightarrow` MET

In order to fully match the gluino and anyBSM nodes their daughters must also be compared (*Step C*). Since their daughters (q,N1) and (MET,jet) are final state nodes (undecayed) the comparison procedure stops at this level and results in the following matches:

 * q :math:`\leftrightarrow` jet
 * N1 :math:`\leftrightarrow` MET

.. _matchB:

.. figure:: images/theoryPredC.png
   :width: 70%
   :align: center

   Illustration of the procedure of matching, step by step.


This result finally means a full match for the (gluino,N1) and (anyBSM,MET) pairs, which then means that the root nodes fully match. Consequently the model and database topologies match (see :numref:`Fig. %s <matchC>`).
The procedure just described can be applied to any pair of |SMS topologies|\ [#f4]_ and can also be applied to :ref:`inclusive topologies <inclusiveSMS>` with small modifications.

.. _matchC:

.. figure:: images/theoryPredD.png
   :width: 50%
   :align: center

   Result of the matching of the model and database topologies and the identification between |particles| (nodes).



Computing Theory Predictions
----------------------------

As discussed in :doc:`Database Definitions <DatabaseDefinitions>`, the SModelS  database allows
for two types of experimental constraints: 
Upper Limit constraints   (see |ULrs|) and Efficiency Map constraints (see |EMrs|). 
Each of them requires different theoretical predictions to be compared against experimental data.

|ULrs| constrains the weight (|sigBR|) of one |element| or sum of |elements|.
Therefore SModelS must compute the theoretical value of |sigBR| summing only over the |elements|
appearing in the respective :ref:`constraint <ULconstraint>`.
This is done by assigning an efficiency equal to 1 (0) to each element,
if the element appears (does not appear) in the :ref:`constraint <ULconstraint>`.
Then the final theoretical prediction is the sum over all
|elements| with a non-zero value of |ssigBRe|. This value can then be compared with the
respective 95% C.L. upper limit extracted from the UL map (see |ULrs|).

On the other hand, |EMrs| constrain the total signal (|ssigBRe|) in a given signal region (|Dataset|).
Consequently, in this case SModelS must compute |sigBRe| for each |element|, using the efficiency maps for
the corresponding |Dataset|. The final theoretical prediction is the sum over all |elements|
with a non-zero value of |sigBRe|.
This value can then be compared with the signal upper limit for the respective 
signal region (|dataset|). 

For experimental results for which the covariance matrix is provided, it
is possible to combine all the signal regions (see :ref:`Combination of Signal Regions <combineSRs>`).
In this case the final theory prediction corresponds to the sum of |sigBRe| over all signal regions (and all elements)
and the upper limit is computed for this sum.

Although the details of the theoretical prediction computation differ depending on the type
of |ExpRes| (|ULrs| or |EMrs|), the overall procedure is common for both types of results. Below we schematically
show the main steps of the theory prediction calculation:

.. _theoPredScheme:

.. image:: images/theoryPredScheme.png
   :width: 90% 


As shown above the procedure can always be divided in two main steps:
*Element Selection* and *Element Clustering*.
Once the |elements| have been selected and clustered, the theory prediction for each |Dataset| is given by
the sum of all the |element| weights (|sigBRe|) belonging to the same cluster:

.. math::
   \mbox{theory prediction } = \sum_{cluster} (\mbox{element weight}) =  \sum_{cluster} (\sigma \times BR \times \epsilon)

Below we describe in detail the *element selection* and *element clustering* 
methods for computing the theory predictions for each type
of |ExpRes| separately.

* **Theory predictions are computed using the** `theoryPredictionsFor <theory.html#theory.theoryPrediction.theoryPredictionsFor>`_ **method** 

.. _thePredUL:

Theory Predictions for Upper Limit Results
------------------------------------------

Computation of the signal cross sections for a given
|ULr| takes place in two steps. First selection of the
|elements| generated by the model :doc:`decomposition <Decomposition>` and then clustering
of the selected elements according to their properties. These two steps are described below.

.. _ULselection:

Element Selection
^^^^^^^^^^^^^^^^^

An |ULr| holds upper limits for the cross sections of an |element|
or sum of |elements|. Consequently, the first step for computing the theory predictions for the corresponding
experimental result is to select the |elements| that appear in the :ref:`UL result constraint <ULconstraint>`.
This is conveniently done attributing to each |element| an efficiency equal to 1 (0) 
if the |element| appears (does not appear) in the :ref:`constraint <ULconstraint>`.
After all the |elements| weights (:math:`\sigma \times BR`) have been rescaled
by these ''trivial'' efficiencies, only the ones with non-zero weights are relevant for the signal
cross section.
The |element| selection is then trivially achieved by selecting all the |elements| with non-zero weights.

The procedure described above is illustrated graphically in the figure below for the simple example where the 
:ref:`constraint <ULconstraint>` is :math:`[[[e^+]],[[e^-]]]\,+\,[[[\mu^+]],[[\mu^-]]]`.

.. image:: images/ULselection.png
   :width: 85% 



* **The element selection is implemented by the** `getElementsFrom <theory.html#theoryPrediction._getElementsFrom>`_ **method**

.. _ULcluster:

Element Clustering
^^^^^^^^^^^^^^^^^^

Naively one would expect that after all the |elements| appearing in the :ref:`constraint <ULconstraint>`
have been selected, it is trivial to compute the theory prediction: one must simply 
sum up the weights (|sigBR|) of all the selected |elements|.
However, the selected |elements| usually differ in their masses and/or widths\ [#f1]_ and the
experimental limit (see :ref:`Upper Limit constraint <ULconstraint>`) assumes that all the |elements| appearing
in the :ref:`constraint <ULconstraint>` have the same efficiency, which typically
implies that the distinct elements have the same mass arrays and widths.
As a result, the selected |elements| must be grouped into *clusters* of equal masses and widths.
When grouping the |elements|, however, one must allow for small differences,
since the experimental efficiencies should not be strongly sensitive to tiny changes in
mass or width values. For instance, assume two |elements| contain identical mass arrays, except
for the parent masses which differ by 1 MeV. In this case it is obvious that for all experimental
purposes the two |elements| have the same mass and should contribute
to the same theory prediction (e.g. their weights should be
added when computing the signal cross section). 
Unfortunately there is no way to unambiguously define ''similar efficiencies''
or ''similar masses and widths'' and the definition should depend on the |ExpRes|.
In the simplest case where the upper limit result corresponds to a single signal region
(which is not always the case), one could assume that each element efficiency is inversely
proportional to its upper limit.
Hence the distance between two |elements| can be defined as the relative
difference between their upper limits, as described in :ref:`element distance <distance>`.
Then, if the :ref:`distance <distance>` between two selected |elements| is smaller
than a maximum value (defined by `maxDist <theory.html#theory.clusterTools.clusterElements>`_),
they are gouped in the same cluster and their cross-sections
will be combined, as illustrated by the example below:



.. image:: images/ULcluster.png
   :width: 80%



Notice that the above definition of distance quantifies the experimental analysis
sensitivity to changes in the |element| properties (masses and widths),
which should correspond to changes in the upper limit value for the |element|.
However, most  |ExpRess| combine distinct signal regions or use a more complex
analysis in order to derive upper limits. In such cases,
two |elements| can have (by chance) the same upper limit value,
but still have very distinct efficiencies and should not be considered similar and combined.
In order to deal with such cases an additional requirement is imposed when clustering two |elements|:
the distance between both elements to the *average element* must also be smaller than
`maxDist <theory.html#theory.clusterTools.clusterElements>`_ .
The *average element* of a list of |elements| corresponds to
the |element| with the same common topology and final states, but with the
mass array and widths replaced by the average mass and width over all the elements in the list.
If this *average element* has an upper limit similar to all the |elements| in the list,
we assume that all the elements have similar efficiencies and can be considered as similar
to the given |ExpRes|.


Once all the |elements| have been clustered, their weights can finally be added together
and compared against the experimental upper limit.



* **The clustering of elements is implemented by the** `clusterElements <theory.html#theory.clusterTools.clusterElements>`_  **method**.

.. _distance:  

Distance Between Elements
^^^^^^^^^^^^^^^^^^^^^^^^^

As mentioned :ref:`above <ULcluster>`, in order to cluster the |elements| it is necessary
to determine whether two |elements| are similar for a given |ExpRes|.
This usually means that both |elements| have similar efficiencies for the |ExpRes|.
Since an absolute definition of ''similar elements'' is not possible and the sensitivity to changes in
the mass or width of a given |element| depends on the experimental result, SModelS uses
an ''upper limit map-dependent'' definition.
Each |element| is mapped to its corresponding upper limit for a given |ExpRes| and the distance between
two elements is simply given by the relative distance between the upper limits:

.. math::

   & \mbox{ Upper Limit}(\mbox{Element } A) = x, \; \mbox{ Upper Limit}(\mbox{Element } B) = y\\
   & \Rightarrow \mbox{distance}(A,B) = \frac{|x-y|}{(x+y)/2}
   


Theory Predictions for Efficiency Map Results
---------------------------------------------

In order to compute the signal cross sections for a given |EMr|, so it can be compared
to the signal region limits, it is first necessary to apply the efficiencies (see |EMr|) to all the |elements| generated
by the model :doc:`decomposition <Decomposition>`.
Notice that typically a single |EMr| contains several signal regions (|Datasets|) and there will be a set of efficiencies
(or efficiency maps) for each |dataset|. As a result, several theory predictions (one for each |dataset|) will be computed.
This procedure is similar (in nature) to 
the :ref:`Element Selection<ULselection>` applied in the case of a |ULr|, except that now it must be repeated 
for several |datasets| (signal regions).


After the |element|'s weights have being rescaled by the corresponding efficiencies for the given |dataset| (signal region),
all of them can be grouped together in a single cluster, which will provide a single theory prediction (signal
cross section) for each |Dataset|. Hence the :ref:`element clustering <EMcluster>` discussed below is completely trivial.
On the other hand the :ref:`element selection <EMselection>` is slightly more involved than in the |ULr|
case and will be discussed in more detail.

.. _EMselection:

Element Selection
^^^^^^^^^^^^^^^^^

The element selection for the case of an |EMr| consists of rescaling all the |elements|
weights by their efficiencies, according to the efficiency map of the corresponding |Dataset|.
The efficiency for a given |Dataset| depends both on the |element| topology and its |particle| content. 
In practice the efficiencies for most of the |elements| will be extremely small (or zero), hence only a subset effectively
contributes after the element selection\ [#f2]_.
In the figure below we illustrate the element selection for the case of an |EMr|/|Dataset|:

.. _EMselectionfig:

.. image:: images/EMselection.png
   :width: 85% 

If, for instance, the analysis being considered vetoes :math:`jets` and :math:`\tau`'s in the final state, 
we will have :math:`\epsilon_2,\, \epsilon_4 \simeq 0` for the example in the :ref:`figure above <EMselectionfig>`.
Also, if the experimental result applies only to prompt decays and the |element| contains intermediate
meta-stable BSM particles, its efficiency will be very small (although not necessarily zero). 


* **The element selection is implemented by the** `getElementsFrom <theory.html#theoryPrediction._getElementsFrom>`_ **method**

.. _EMcluster:

Element Clustering
^^^^^^^^^^^^^^^^^^

After the efficiencies have been
applied to the element's weights, all the |elements| can be combined together when computing
the theory prediction for the given |Dataset| (signal region). Since a given signal region
correspond to the same signal upper limit for any |element|,
the :ref:`distance <distance>` between any two |elements| for an |EMr| is always zero and
the clustering procedure described :ref:`above <ULcluster>`
will trivially group together all the selected |elements| into a single cluster:

.. image:: images/EMcluster.png
   :width: 80%

* **The clustering of elements is implemented by the** `clusterElements <theory.html#theory.clusterTools.clusterElements>`_  **method**.

.. [#f1] When refering to an |element| mass or width, we mean all the masses
   and widths of the Z\ :sub:`2`-odd |particles| appearing in the |element|. Two |elements| are considered to have identical
   masses and widths if their mass arrays and width arrays are identical.
.. [#f2] The number of |elements| passing the selection also depends on the availability of efficiency maps
   for the |elements| generated by the decomposition. Whenever there are no efficiencies available for an
   element, the efficiency is taken to be zero.
.. [#f3] The comparison of the |particle| properties is done only for the properties which have been defined for both |particles|. For instance, it is often the case that the spin property is not defined for particles appearing in the database topologies, so this property will be ignored when comparing particles from the model topology and to the ones from the database topology.
.. [#f4] In order to comparing two sets of daughters (mapped to a bipartite graph) irrespective of their ordering, a `maximal matching algorithm <https://en.wikipedia.org/wiki/Hopcroft%E2%80%93Karp_algorithm>`_ is used. Note that it is possible that the matching is not unique (i.e. :math:`A \leftrightarrow a, B \leftrightarrow b` and :math:`A \leftrightarrow b, B \leftrightarrow a`) and in this case the matching procedure is not deterministic.
