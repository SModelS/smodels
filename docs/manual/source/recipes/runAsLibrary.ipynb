{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How To: Run SModelS as a python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the path to SModelS installation folder\n",
    "import sys; sys.path.append(\".\"); import smodels_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smodels.base import runtime\n",
    "#Define your model (list of rEven and rOdd particles)\n",
    "runtime.modelFile = 'smodels.share.models.mssm' \n",
    "\n",
    "from smodels.decomposition import decomposer\n",
    "from smodels.base.physicsUnits import fb, GeV, TeV\n",
    "from smodels.matching.theoryPrediction import theoryPredictionsFor\n",
    "from smodels.experiment.databaseObj import Database\n",
    "from smodels.tools import coverage\n",
    "from smodels.base.smodelsLogging import setLogLevel\n",
    "from smodels.share.models.mssm import BSMList                                                   \n",
    "from smodels.share.models.SMparticles import SMList                                           \n",
    "from smodels.base.model import Model\n",
    "setLogLevel(\"info\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO in model.updateParticles() in 428: Loaded 62 BSM particles\n"
     ]
    }
   ],
   "source": [
    "model = Model(BSMparticles=BSMList, SMparticles=SMList)\n",
    " \n",
    "slhafile = 'inputFiles/slha/lightEWinos.slha'\n",
    "model.updateParticles ( inputFile = slhafile )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decompose the input model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Decomposition Results: \n",
      "\t  Total number of topologies: 39 \n",
      "\t  Total number of elements = 6055 \n"
     ]
    }
   ],
   "source": [
    "# Set main options for decomposition\n",
    "sigmacut = 0.1 * fb\n",
    "mingap = 5. * GeV\n",
    "# Decompose model (use slhaDecomposer for SLHA input or lheDecomposer for LHE input)\n",
    "toplist = decomposer.decompose(model, sigmacut, massCompress=True, invisibleCompress=True, minmassgap=mingap)\n",
    "\n",
    "# Access basic information from decomposition, using the topology list and topology objects:\n",
    "print( \"\\n Decomposition Results: \" )\n",
    "print( \"\\t  Total number of topologies: %i \" %len(toplist) )\n",
    "nel = len(toplist.getSMSList())\n",
    "print( \"\\t  Total number of elements = %i \" %nel )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Database of experimental results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO in databaseObj.loadBinaryFile() in 551: loading binary db file /home/lessa/.cache/smodels/official300.pcl format version 214\n",
      "INFO in databaseObj.loadBinaryFile() in 558: Loaded database from /home/lessa/.cache/smodels/official300.pcl in 2.0 secs.\n"
     ]
    }
   ],
   "source": [
    "# Set the path to the database\n",
    "database = Database(\"official\")\n",
    "# Load the experimental results to be used.\n",
    "# In this case, all results are employed.\n",
    "listOfExpRes = database.getExpResults( analysisIDs = [ \"ATLAS-SUSY-2015-06\" ])\n",
    "\n",
    "# Print basic information about the results loaded.\n",
    "# Count the number of loaded UL and EM experimental results:\n",
    "nUL, nEM = 0, 0\n",
    "for exp in listOfExpRes:\n",
    "    # expType = exp.getValuesFor('dataType')[0]\n",
    "    expType = exp.datasets[0].dataInfo.dataType\n",
    "    if expType == 'upperLimit':\n",
    "        nUL += 1\n",
    "    elif  expType == 'efficiencyMap':\n",
    "        nEM += 1\n",
    "# print(\"\\n Loaded Database with %i UL results and %i EM results \" %(nUL,nEM))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match the decomposed simplified models with the experimental database of constraints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Theory Predictions and Constraints:\n",
      "\n",
      " ATLAS-SUSY-2015-06 \n",
      "------------------------\n",
      "Dataset =  SR5j\n",
      "TxNames =  ['T1']\n",
      "Theory Prediction =  2.76E-06 [pb]\n",
      "Condition Violation =  None\n",
      "UL for theory prediction =  1.79E+00 [fb]\n",
      "r = 1.544E-03\n",
      "L_BSM, L_SM, L_max = 7.191E-03, 7.215E-03, 7.215E-03\n",
      "\n",
      "The largest r-value (theory/upper limit ratio) is  0.0015440823356560514\n",
      "(The input model is not excluded by the simplified model results)\n"
     ]
    }
   ],
   "source": [
    "# Compute the theory predictions for each experimental result and print them:\n",
    "print(\"\\n Theory Predictions and Constraints:\")\n",
    "rmax = 0.\n",
    "bestResult = None\n",
    "allPredictions = theoryPredictionsFor(database, toplist, combinedResults=False)\n",
    "predsDict = {}\n",
    "for tp in allPredictions:\n",
    "    anaID = tp.analysisId()\n",
    "    if anaID not in predsDict:\n",
    "        predsDict[anaID] = []\n",
    "    predsDict[anaID].append(tp)\n",
    "\n",
    "\n",
    "for anaID,predictions in predsDict.items():\n",
    "    if not predictions:\n",
    "        continue  # Skip if there are no constraints from this result\n",
    "    print('\\n %s ' % anaID)\n",
    "    for theoryPrediction in predictions:\n",
    "        dataset = theoryPrediction.dataset\n",
    "        datasetID = theoryPrediction.dataId()\n",
    "        txnames = sorted([str(txname) for txname in theoryPrediction.txnames])\n",
    "        print(\"------------------------\")\n",
    "        print(\"Dataset = \", datasetID)  # Analysis name\n",
    "        print(\"TxNames = \", txnames)\n",
    "        print(\"Theory Prediction = \", theoryPrediction.xsection)  # Signal cross section\n",
    "        print(\"Condition Violation = \", theoryPrediction.conditions)  # Condition violation values\n",
    "\n",
    "        # Get the corresponding upper limit:\n",
    "        print(\"UL for theory prediction = \", theoryPrediction.upperLimit)\n",
    "\n",
    "        # Compute the r-value\n",
    "        r = theoryPrediction.getRValue()\n",
    "        print(\"r = %1.3E\" % r)\n",
    "        # Compute likelihoods for EM-type results:\n",
    "        if dataset.getType() == 'efficiencyMap':\n",
    "            theoryPrediction.computeStatistics()\n",
    "            print('L_BSM, L_SM, L_max = %1.3E, %1.3E, %1.3E' % (theoryPrediction.likelihood(),\n",
    "                  theoryPrediction.lsm(), theoryPrediction.lmax()))\n",
    "        if r > rmax:\n",
    "            rmax = r\n",
    "            bestResult = anaID\n",
    "\n",
    "# Print the most constraining experimental result\n",
    "print( \"\\nThe largest r-value (theory/upper limit ratio) is \",rmax )\n",
    "if rmax > 1.:\n",
    "    print( \"(The input model is likely excluded by %s)\" %bestResult )\n",
    "else:\n",
    "    print( \"(The input model is not excluded by the simplified model results)\" )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for simplified models in the input model which were not tested by the Database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total cross-section for missing topologies (fb):  3.672E+03\n",
      "\n",
      "\n",
      "Total cross-section for missing topologies with displaced decays (fb):  0.000E+00\n",
      "\n",
      "\n",
      "Total cross-section for missing topologies with prompt decays (fb):  3.672E+03\n",
      "\n",
      "\n",
      "Total cross-section for topologies outside the grid (fb):  1.530E+03\n",
      "\n",
      "Missing topologies (up to 3):\n",
      "Element: PV > (jet,jet,MET), (nu,l,MET)\n",
      "\tcross-section (fb): 644.0092445884675\n",
      "Element: PV > (jet,jet,MET), (nu,ta,MET)\n",
      "\tcross-section (fb): 321.1539651599444\n",
      "Element: PV > (jet,jet,MET), (b,b,MET)\n",
      "\tcross-section (fb): 274.0877573459048\n",
      "\n",
      "No displaced decays\n"
     ]
    }
   ],
   "source": [
    "#Find out missing topologies for sqrts=8*TeV:             \n",
    "uncovered = coverage.Uncovered(toplist,sqrts=8.*TeV)\n",
    "#First sort coverage groups by label                                          \n",
    "groups = sorted(uncovered.groups[:], key = lambda g: g.label)\n",
    "#Print uncovered cross-sections:                             \n",
    "for group in groups:\n",
    "    print(\"\\nTotal cross-section for %s (fb): %10.3E\\n\" %(group.description,group.getTotalXSec()))\n",
    "\n",
    "missingTopos = uncovered.getGroup('missing (prompt)')\n",
    "#Print some of the missing topologies:\n",
    "if missingTopos.finalStateSMS:\n",
    "    print('Missing topologies (up to 3):' )\n",
    "    for genEl in missingTopos.finalStateSMS[:3]:\n",
    "        print('Element:', genEl)\n",
    "        print('\\tcross-section (fb):', genEl.missingX)\n",
    "else:\n",
    "    print(\"No missing topologies found\\n\")\n",
    "\n",
    "missingDisplaced = uncovered.getGroup('missing (displaced)')\n",
    "#Print elements with displaced decays:                              \n",
    "if missingDisplaced.finalStateSMS:\n",
    "    print('\\nElements with displaced vertices (up to 2):' )\n",
    "    for genEl in missingDisplaced.finalStateSMS[:2]:                                    \n",
    "        print('Element:', genEl)                                                          \n",
    "        print('\\tcross-section (fb):', genEl.missingX)                                    \n",
    "else:                                                                                     \n",
    "    print(\"\\nNo displaced decays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
