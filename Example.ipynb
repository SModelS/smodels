{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e68930e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "from __future__ import print_function\n",
    "from smodels.base import runtime\n",
    "# Define your model (list of BSM particles)\n",
    "runtime.modelFile = 'smodels.share.models.mssm'\n",
    "# runtime.modelFile = 'mssmQNumbers.slha'\n",
    "\n",
    "from smodels.decomposition import decomposer\n",
    "from smodels.base.physicsUnits import fb, GeV, TeV\n",
    "from smodels.matching.theoryPrediction import theoryPredictionsFor\n",
    "from smodels.experiment.databaseObj import Database\n",
    "from smodels.tools import coverage\n",
    "from smodels.matching.theoryPredictionsCombiner import TheoryPredictionsCombiner\n",
    "from smodels.base.smodelsLogging import setLogLevel\n",
    "from smodels.share.models.mssm import BSMList\n",
    "from smodels.share.models.SMparticles import SMList\n",
    "from smodels.base.model import Model\n",
    "import time\n",
    "import os\n",
    "setLogLevel(\"info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed387104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO in databaseObj.loadBinaryFile() in 527: loading binary db file /home/lessa/.cache/smodels/official300-beta.pcl format version 214\n",
      "INFO in databaseObj.loadBinaryFile() in 534: Loaded database from /home/lessa/.cache/smodels/official300-beta.pcl in 0.7 secs.\n"
     ]
    }
   ],
   "source": [
    "# Set the path to the database\n",
    "database = Database('official')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c38e24dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO in model.updateParticles() in 414: Loaded 62 BSM particles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Decomposition done in 0.04m\n",
      "\n",
      " Decomposition Results: \n",
      "\t  Total number of topologies: 30 \n",
      "\t  Total number of elements = 1742 \n",
      "\t\t 110110101000 topology  = \n",
      "\t\t 0-th element  =  (PV > N1,C1-(1)), (C1-(1) > N1~,e-,nu)\n",
      "\t\t\twith final states = [1, 3, 4, 5] \n",
      "\t\t\twith cross section = ['1.30E+01 [TeV]:7.03E-03 [pb] (-1000024, 1000022)', '8.00E+00 [TeV]:4.03E-03 [pb] (-1000024, 1000022)'] \n",
      "\t\t\tand masses =  [None, 6.81E+01 [GeV], 1.34E+02 [GeV], 6.81E+01 [GeV], 5.00E-01 [MeV], 0.00E+00 [MeV]]\n"
     ]
    }
   ],
   "source": [
    "model = Model(BSMparticles=BSMList, SMparticles=SMList)\n",
    "slhafile = 'inputFiles/slha/lightEWinos.slha'\n",
    "model.updateParticles(inputFile=slhafile)\n",
    "\n",
    "# Set main options for decomposition\n",
    "sigmacut = 0.5*fb\n",
    "mingap = 5.*GeV\n",
    "\n",
    "t0 = time.time()\n",
    "# Decompose model\n",
    "topDict = decomposer.decompose(model, sigmacut,\n",
    "                               massCompress=True, invisibleCompress=True,\n",
    "                               minmassgap=mingap)\n",
    "\n",
    "# Access basic information from decomposition, using the topology list and topology objects:\n",
    "print(\"\\n Decomposition done in %1.2fm\" %((time.time()-t0)/60.))\n",
    "print(\"\\n Decomposition Results: \")\n",
    "print(\"\\t  Total number of topologies: %i \" % len(topDict))\n",
    "nel = len(topDict.getSMSList())\n",
    "print(\"\\t  Total number of elements = %i \" % nel)\n",
    "# Print information about the m-th topology:\n",
    "m = 2\n",
    "if len(topDict) > m:\n",
    "    cName = sorted(topDict.keys())[m]\n",
    "    elementList = topDict[cName]\n",
    "    print(\"\\t\\t %i topology  = \" % cName)\n",
    "    # Print information about the n-th element in the m-th topology:\n",
    "    n = 0\n",
    "    el = elementList[n]\n",
    "    print(\"\\t\\t %i-th element  = \" % (n), el, end=\"\")\n",
    "    print(\"\\n\\t\\t\\twith final states =\", el.getFinalStates(), \"\\n\\t\\t\\twith cross section =\", el.weightList, \"\\n\\t\\t\\tand masses = \", el.mass)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b0a8565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(PV > N1,N1)\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"98pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 98.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-112 94,-112 94,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"darkgray\" stroke=\"darkgray\" cx=\"45\" cy=\"-90\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"45\" y=\"-87.5\" font-family=\"Times,serif\" font-size=\"10.00\">PV</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"lightcoral\" stroke=\"lightcoral\" cx=\"18\" cy=\"-18\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"18\" y=\"-15.5\" font-family=\"Times,serif\" font-size=\"10.00\">N1</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M38.74,-72.76C35.5,-64.37 31.47,-53.93 27.83,-44.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"31.09,-43.22 24.23,-35.15 24.56,-45.74 31.09,-43.22\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"lightcoral\" stroke=\"lightcoral\" cx=\"72\" cy=\"-18\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"72\" y=\"-15.5\" font-family=\"Times,serif\" font-size=\"10.00\">N1</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M51.26,-72.76C54.5,-64.37 58.53,-53.93 62.17,-44.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"65.44,-45.74 65.77,-35.15 58.91,-43.22 65.44,-45.74\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fc4e0f1dcf0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sms = topDict.getSMSList()[0]\n",
    "print(sms)\n",
    "sms.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25b20426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Loaded Database with 97 UL results and 48 EM results \n",
      "\n",
      " Theory Predictions and Constraints:\n",
      "\n",
      " ATLAS-SUSY-2019-09 \n",
      "------------------------\n",
      "Dataset =  None\n",
      "TxNames =  ['TChiWZoff']\n",
      "Theory Prediction =  2.63E+00 [pb]\n",
      "Condition Violation =  [0.0]\n",
      "UL for theory prediction =  5.49E+02 [fb]\n",
      "r = 4.783E+00\n",
      "\n",
      "The largest r-value (theory/upper limit ratio) is 4.783E+00\n",
      "(The input model is likely excluded by ATLAS-SUSY-2019-09)\n",
      "\n",
      " Theory Predictions done in 0.09m\n",
      "\n",
      " ATLAS-SUSY-2019-09 \n",
      "------------------------\n",
      "Dataset =  SRhigh_0Jf1\n",
      "TxNames =  ['TChiWZoff']\n",
      "Theory Prediction =  3.47E-04 [pb]\n",
      "Condition Violation =  None\n",
      "UL for theory prediction =  1.20E-01 [fb]\n",
      "r = 2.888E+00\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataSet' object has no attribute 'likelihood'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Compute likelihoods for EM-type results:\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mgetType() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mefficiencyMap\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 41\u001b[0m     \u001b[43mtheoryPrediction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomputeStatistics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL_BSM, L_SM, L_max = \u001b[39m\u001b[38;5;132;01m%1.3E\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%1.3E\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%1.3E\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (theoryPrediction\u001b[38;5;241m.\u001b[39mlikelihood(),\n\u001b[1;32m     43\u001b[0m             theoryPrediction\u001b[38;5;241m.\u001b[39mlsm(), theoryPrediction\u001b[38;5;241m.\u001b[39mlmax()))\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;241m>\u001b[39m rmax:\n",
      "File \u001b[0;32m~/smodels-graphs/smodels/matching/theoryPrediction.py:373\u001b[0m, in \u001b[0;36mTheoryPrediction.computeStatistics\u001b[0;34m(self, expected, allowNegativeSignals)\u001b[0m\n\u001b[1;32m    371\u001b[0m lumi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mgetLumi()\n\u001b[1;32m    372\u001b[0m nsig \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxsection\u001b[38;5;241m*\u001b[39mlumi)\u001b[38;5;241m.\u001b[39masNumber()\n\u001b[0;32m--> 373\u001b[0m llhd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlikelihood\u001b[49m(nsig, marginalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmarginalize,\n\u001b[1;32m    374\u001b[0m                                deltas_rel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeltas_rel,\n\u001b[1;32m    375\u001b[0m                                expected\u001b[38;5;241m=\u001b[39mexpected)\n\u001b[1;32m    376\u001b[0m llhd_sm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mlikelihood(nsig\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, marginalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmarginalize,\n\u001b[1;32m    377\u001b[0m                                   deltas_rel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeltas_rel,\n\u001b[1;32m    378\u001b[0m                                   expected\u001b[38;5;241m=\u001b[39mexpected)\n\u001b[1;32m    379\u001b[0m llhd_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mlmax(marginalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmarginalize,\n\u001b[1;32m    380\u001b[0m                              deltas_rel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeltas_rel,\n\u001b[1;32m    381\u001b[0m                              allowNegativeSignals\u001b[38;5;241m=\u001b[39mallowNegativeSignals,\n\u001b[1;32m    382\u001b[0m                              expected\u001b[38;5;241m=\u001b[39mexpected)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataSet' object has no attribute 'likelihood'"
     ]
    }
   ],
   "source": [
    "# Load the experimental results to be used.\n",
    "# In this case, all results are employed.\n",
    "listOfExpRes = database.getExpResults()\n",
    "\n",
    "t0 = time.time()\n",
    "# Print basic information about the results loaded.\n",
    "# Count the number of loaded UL and EM experimental results:\n",
    "nUL, nEM = 0, 0\n",
    "for exp in listOfExpRes:\n",
    "    expType = exp.datasets[0].dataInfo.dataType\n",
    "    if expType == 'upperLimit':\n",
    "        nUL += 1\n",
    "    elif expType == 'efficiencyMap':\n",
    "        nEM += 1\n",
    "print(\"\\n Loaded Database with %i UL results and %i EM results \" % (nUL, nEM))\n",
    "\n",
    "# Compute the theory predictions for each experimental result and print them:\n",
    "print(\"\\n Theory Predictions and Constraints:\")\n",
    "rmax = 0.\n",
    "bestResult = None\n",
    "allPredictions = theoryPredictionsFor(database, topDict, combinedResults=False, marginalize=False)\n",
    "for theoryPrediction in allPredictions:\n",
    "    print('\\n %s ' % theoryPrediction.analysisId())\n",
    "    dataset = theoryPrediction.dataset\n",
    "    datasetID = theoryPrediction.dataId()\n",
    "    txnames = sorted([str(txname) for txname in theoryPrediction.txnames])\n",
    "    print(\"------------------------\")\n",
    "    print(\"Dataset = \", datasetID)  # Analysis name\n",
    "    print(\"TxNames = \", txnames)\n",
    "    print(\"Theory Prediction = \", theoryPrediction.xsection)  # Signal cross section\n",
    "    print(\"Condition Violation = \", theoryPrediction.conditions)  # Condition violation values\n",
    "\n",
    "    # Get the corresponding upper limit:\n",
    "    print(\"UL for theory prediction = \", theoryPrediction.upperLimit)\n",
    "\n",
    "    # Compute the r-value\n",
    "    r = theoryPrediction.getRValue()\n",
    "    print(\"r = %1.3E\" % r)\n",
    "    # Compute likelihoods for EM-type results:\n",
    "    if dataset.getType() == 'efficiencyMap':\n",
    "        theoryPrediction.computeStatistics()\n",
    "        print('L_BSM, L_SM, L_max = %1.3E, %1.3E, %1.3E' % (theoryPrediction.likelihood(),\n",
    "                theoryPrediction.lsm(), theoryPrediction.lmax()))\n",
    "    if r > rmax:\n",
    "        rmax = r\n",
    "        bestResult = theoryPrediction.analysisId()\n",
    "\n",
    "    # Print the most constraining experimental result\n",
    "    print(\"\\nThe largest r-value (theory/upper limit ratio) is %1.3E\" % rmax)\n",
    "    if rmax > 1.:\n",
    "        print(\"(The input model is likely excluded by %s)\" % bestResult)\n",
    "    else:\n",
    "        print(\"(The input model is not excluded by the simplified model results)\")\n",
    "\n",
    "    print(\"\\n Theory Predictions done in %1.2fm\" %((time.time()-t0)/60.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ec0ae0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = allPredictions[0]\n",
    "smsList = tp.smsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4ca4d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(PV > N2(1),C1+(2)), (N2(1) > N1,mu-,mu+), (C1+(2) > N1,e+,nu)\n",
      "5.91E-03 [pb]\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"314pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 314.00 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-184 310,-184 310,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"darkgray\" stroke=\"darkgray\" cx=\"153\" cy=\"-162\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"153\" y=\"-159.5\" font-family=\"Times,serif\" font-size=\"10.00\">PV</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"lightcoral\" stroke=\"lightcoral\" cx=\"99\" cy=\"-90\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-87.5\" font-family=\"Times,serif\" font-size=\"10.00\">N2</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M142.33,-147.17C134.79,-137.39 124.52,-124.08 115.87,-112.87\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"118.53,-110.58 109.65,-104.8 112.98,-114.86 118.53,-110.58\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"lightcoral\" stroke=\"lightcoral\" cx=\"207\" cy=\"-90\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"207\" y=\"-87.5\" font-family=\"Times,serif\" font-size=\"10.00\">C1+</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M163.67,-147.17C171.21,-137.39 181.48,-124.08 190.13,-112.87\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"193.02,-114.86 196.35,-104.8 187.47,-110.58 193.02,-114.86\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"lightcoral\" stroke=\"lightcoral\" cx=\"18\" cy=\"-18\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"18\" y=\"-15.5\" font-family=\"Times,serif\" font-size=\"10.00\">N1</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M85.62,-77.44C72.89,-66.43 53.52,-49.7 38.77,-36.95\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"40.98,-34.23 31.13,-30.34 36.4,-39.53 40.98,-34.23\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<ellipse fill=\"skyblue\" stroke=\"skyblue\" cx=\"72\" cy=\"-18\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"72\" y=\"-15.5\" font-family=\"Times,serif\" font-size=\"10.00\">mu&#45;</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>1&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M92.74,-72.76C89.5,-64.37 85.47,-53.93 81.83,-44.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"85.09,-43.22 78.23,-35.15 78.56,-45.74 85.09,-43.22\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<ellipse fill=\"skyblue\" stroke=\"skyblue\" cx=\"126\" cy=\"-18\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"126\" y=\"-15.5\" font-family=\"Times,serif\" font-size=\"10.00\">mu+</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>1&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M105.26,-72.76C108.5,-64.37 112.53,-53.93 116.17,-44.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"119.44,-45.74 119.77,-35.15 112.91,-43.22 119.44,-45.74\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<ellipse fill=\"lightcoral\" stroke=\"lightcoral\" cx=\"180\" cy=\"-18\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"180\" y=\"-15.5\" font-family=\"Times,serif\" font-size=\"10.00\">N1</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>2&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M200.74,-72.76C197.5,-64.37 193.47,-53.93 189.83,-44.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"193.09,-43.22 186.23,-35.15 186.56,-45.74 193.09,-43.22\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<ellipse fill=\"skyblue\" stroke=\"skyblue\" cx=\"234\" cy=\"-18\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"234\" y=\"-15.5\" font-family=\"Times,serif\" font-size=\"10.00\">e+</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>2&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M213.26,-72.76C216.5,-64.37 220.53,-53.93 224.17,-44.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"227.44,-45.74 227.77,-35.15 220.91,-43.22 227.44,-45.74\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<ellipse fill=\"skyblue\" stroke=\"skyblue\" cx=\"288\" cy=\"-18\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"288\" y=\"-15.5\" font-family=\"Times,serif\" font-size=\"10.00\">nu</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>2&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M220.38,-77.44C233.11,-66.43 252.48,-49.7 267.23,-36.95\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"269.6,-39.53 274.87,-30.34 265.02,-34.23 269.6,-39.53\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fc4de3c8b80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(smsList[0])\n",
    "print(smsList[0].weight)\n",
    "smsList[0].draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "571be06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Combined analyses: ATLAS-SUSY-2013-11,CMS-SUS-13-013\n",
      "Combined r value: 2.183E-02\n",
      "Combined r value (expected): 2.183E-02\n",
      "Likelihoods: L, L_max, L_SM =  1.385E-02,  1.401E-02,  1.394E-02\n",
      "\n",
      "\n",
      " Combination of analyses done in 0.00m\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "# Select a few results results for combination:\n",
    "combineAnas = ['ATLAS-SUSY-2013-11', 'CMS-SUS-13-013']\n",
    "selectedTheoryPreds = []\n",
    "for tp in allPredictions:\n",
    "    expID = tp.analysisId()\n",
    "    if expID not in combineAnas:\n",
    "        continue\n",
    "    if tp.likelihood() is None:\n",
    "        continue\n",
    "    selectedTheoryPreds.append(tp)\n",
    "# Make sure each analysis appears only once:\n",
    "expIDs = [tp.analysisId() for tp in selectedTheoryPreds]\n",
    "if len(expIDs) != len(set(expIDs)):\n",
    "    print(\"\\nDuplicated results when trying to combine analyses. Combination will be skipped.\")\n",
    "# Only compute combination if at least two results were selected\n",
    "elif len(selectedTheoryPreds) > 1:\n",
    "    combiner = TheoryPredictionsCombiner(selectedTheoryPreds)\n",
    "    combiner.computeStatistics()\n",
    "    llhd = combiner.likelihood()\n",
    "    lmax = combiner.lmax()\n",
    "    lsm = combiner.lsm()\n",
    "    print(\"\\n\\nCombined analyses:\", combiner.analysisId())\n",
    "    print(\"Combined r value: %1.3E\" % combiner.getRValue())\n",
    "    print(\"Combined r value (expected): %1.3E\" % combiner.getRValue(expected=True))\n",
    "    print(\"Likelihoods: L, L_max, L_SM = %10.3E, %10.3E, %10.3E\\n\" % (llhd, lmax, lsm))\n",
    "\n",
    "print(\"\\n Combination of analyses done in %1.2fm\" %((time.time()-t0)/60.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "127fa69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Coverage done in 0.77m\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "# Find out missing topologies for sqrts=13*TeV:\n",
    "uncovered = coverage.Uncovered(topDict, sqrts=13.*TeV)\n",
    "print(\"\\n Coverage done in %1.2fm\" %((time.time()-t0)/60.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e4a9e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total cross-section for missing topologies (fb):  1.120E+04\n",
      "\n",
      "\n",
      "Total cross-section for missing topologies with displaced decays (fb):  0.000E+00\n",
      "\n",
      "\n",
      "Total cross-section for missing topologies with prompt decays (fb):  1.399E+04\n",
      "\n",
      "\n",
      "Total cross-section for topologies outside the grid (fb):  3.746E+03\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First sort coverage groups by label\n",
    "groups = sorted(uncovered.groups[:], key=lambda g: g.label)\n",
    "# Print uncovered cross-sections:\n",
    "for group in groups:\n",
    "    print(\"\\nTotal cross-section for %s (fb): %10.3E\\n\" % (group.description, group.getTotalXSec()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fa1c9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing topologies (up to 3):\n",
      "Element: (PV > MET,MET,jet,jet,l,nu)\n",
      "\tcross-section (fb): 1203.8783553949456\n",
      "Element: (PV > MET,MET,jet,jet,ta,nu)\n",
      "\tcross-section (fb): 600.4536496545026\n",
      "Element: (PV > MET,MET,jet,jet,jet,jet,t,b,b,b)\n",
      "\tcross-section (fb): 515.0638147985978\n"
     ]
    }
   ],
   "source": [
    "missingTopos = uncovered.getGroup('missing (prompt)')\n",
    "# Print some of the missing topologies:\n",
    "if missingTopos.finalStateSMS:\n",
    "    print('Missing topologies (up to 3):')\n",
    "    for genEl in missingTopos.finalStateSMS[:3]:\n",
    "        print('Element:', genEl)\n",
    "        print('\\tcross-section (fb):', genEl.missingX)\n",
    "else:\n",
    "    print(\"No missing topologies found\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f564ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No displaced decays\n"
     ]
    }
   ],
   "source": [
    "missingDisplaced = uncovered.getGroup('missing (displaced)')\n",
    "# Print elements with displaced decays:\n",
    "if missingDisplaced.finalStateSMS:\n",
    "    print('\\nElements with displaced vertices (up to 2):')\n",
    "    for genEl in missingDisplaced.finalStateSMS[:2]:\n",
    "        print('Element:', genEl)\n",
    "        print('\\tcross-section (fb):', genEl.missingX)\n",
    "else:\n",
    "    print(\"\\nNo displaced decays\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77a2bae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
