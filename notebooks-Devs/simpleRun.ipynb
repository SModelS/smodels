{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO in databaseObj.loadBinaryFile() in 503: loading binary db file /home/lessa/smodels-database/db31.pcl format version 214\n",
      "INFO in databaseObj.loadBinaryFile() in 510: Loaded database from /home/lessa/smodels-database/db31.pcl in 2.0 secs.\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "sys.path.append('../')\n",
    "from smodels.tools import runtime\n",
    "# Define your model (list of BSM particles)\n",
    "runtime.modelFile = 'smodels.share.models.mssm'\n",
    "# runtime.modelFile = 'mssmQNumbers.slha'\n",
    "\n",
    "from smodels.theory import decomposer\n",
    "from smodels.tools.physicsUnits import fb, GeV, TeV\n",
    "from smodels.theory.theoryPrediction import theoryPredictionsFor\n",
    "from smodels.experiment.databaseObj import Database\n",
    "from smodels.tools import coverage\n",
    "from smodels.tools.theoryPredictionsCombiner import TheoryPredictionsCombiner\n",
    "from smodels.tools.smodelsLogging import setLogLevel\n",
    "from smodels.particlesLoader import BSMList\n",
    "from smodels.share.models.SMparticles import SMList\n",
    "from smodels.theory.model import Model\n",
    "setLogLevel(\"info\")\n",
    "\n",
    "# Set the path to the database\n",
    "database = Database(os.path.expanduser(\"~/smodels-database\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO in model.updateParticles() in 383: Loaded 62 BSM particles\n"
     ]
    }
   ],
   "source": [
    "slhafile = '../inputFiles/slha/simplyGluino.slha'\n",
    "model = Model(BSMparticles=BSMList, SMparticles=SMList)\n",
    "model.updateParticles(inputFile=slhafile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set main options for decomposition\n",
    "sigmacut = 0.005*fb\n",
    "mingap = 5.*GeV\n",
    "\n",
    "# Decompose model\n",
    "topDict = decomposer.decompose(model, sigmacut,\n",
    "                               massCompress=True, invisibleCompress=True,\n",
    "                               minmassgap=mingap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Access basic information from decomposition, using the topology list and topology objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Decomposition Results: \n",
      "\t  Total number of topologies: 1 \n",
      "\t  Total number of elements = 1 \n",
      "\t\t 111010100110101000 topology:\n",
      "\t\t 0-th element  =  (PV > gluino(1),gluino(2)), (gluino(1) > N1,q,q), (gluino(2) > N1,q,q)\n",
      "\t\t\twith final states = [N1, N1, q, q, q, q] \n",
      "\t\t\twith cross section = ['1.30E+01 [TeV]:4.31E+00 [pb] (1000021, 1000021)', '8.00E+00 [TeV]:5.72E-01 [pb] (1000021, 1000021)'] \n",
      "\t\t\tand masses =  [None, 6.75E+02 [GeV], 6.75E+02 [GeV], 2.00E+02 [GeV], 0.00E+00 [MeV], 0.00E+00 [MeV], 2.00E+02 [GeV], 0.00E+00 [MeV], 0.00E+00 [MeV]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n Decomposition Results: \")\n",
    "print(\"\\t  Total number of topologies: %i \" % len(topDict))\n",
    "nel = len(topDict.getElements())\n",
    "print(\"\\t  Total number of elements = %i \" % nel)\n",
    "# Print information about the m-th topology:\n",
    "m = 0\n",
    "if len(topDict) > m:\n",
    "    cName = sorted(topDict.keys())[m]\n",
    "    elementList = topDict[cName]\n",
    "    print(\"\\t\\t %i topology:\" % cName)\n",
    "    # Print information about the n-th element in the m-th topology:\n",
    "    n = 0\n",
    "    el = elementList[n]\n",
    "    print(\"\\t\\t %i-th element  = \" % (n), el, end=\"\")\n",
    "    print(\"\\n\\t\\t\\twith final states =\", el.tree.getFinalStates(), \"\\n\\t\\t\\twith cross section =\", el.weight, \"\\n\\t\\t\\tand masses = \", el.mass)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the experimental results to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Loaded Database with 125 UL results and 60 EM results \n"
     ]
    }
   ],
   "source": [
    "listOfExpRes = database.getExpResults()\n",
    "\n",
    "# Print basic information about the results loaded.\n",
    "# Count the number of loaded UL and EM experimental results:\n",
    "nUL, nEM = 0, 0\n",
    "for exp in listOfExpRes:\n",
    "    expType = exp.datasets[0].dataInfo.dataType\n",
    "    if expType == 'upperLimit':\n",
    "        nUL += 1\n",
    "    elif expType == 'efficiencyMap':\n",
    "        nEM += 1\n",
    "print(\"\\n Loaded Database with %i UL results and %i EM results \" % (nUL, nEM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the theory predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Theory Predictions and Constraints:\n",
      "\n",
      " ATLAS-SUSY-2015-06 \n",
      "------------------------\n",
      "Dataset =  SR5j\n",
      "TxNames =  ['T1']\n",
      "Prediction Mass =  [None, 6.75E+02 [GeV], 6.75E+02 [GeV], 0.00E+00 [MeV], 0.00E+00 [MeV], 2.00E+02 [GeV], 0.00E+00 [MeV], 0.00E+00 [MeV], 2.00E+02 [GeV]]\n",
      "Prediction PIDs =  [[None, 1000021, 1000021, [-2, 1, 3, -1, -3, 2], [-2, 1, 3, -1, -3, 2], 1000022, [-2, 1, 3, -1, -3, 2], [-2, 1, 3, -1, -3, 2], 1000022]]\n",
      "Theory Prediction =  1.30E+01 [TeV]:3.55E-02 [pb] (1000021, 1000021)\n",
      "Condition Violation =  None\n",
      "UL for theory prediction =  1.79E+00 [fb]\n",
      "r = 1.981E+01\n",
      "L_BSM, L_SM, L_max = 1.610E-44, 7.215E-03, 7.215E-03\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'jet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_47290/2237913699.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mallPredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mexpResult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistOfExpRes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheoryPredictionsFor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpResult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombinedResults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarginalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mcontinue\u001b[0m  \u001b[0;31m# Skip if there are no constraints from this result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/smodels-graphs/notebooks-Devs/../smodels/theory/theoryPrediction.py\u001b[0m in \u001b[0;36mtheoryPredictionsFor\u001b[0;34m(expResult, smsTopList, maxMassDist, useBestDataset, combinedResults, marginalize, deltas_rel)\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0;31m# Compute predictions for each data set (for UL analyses there is one single set)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexpResult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m         \u001b[0mpredList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_getDataSetPredictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmsTopList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxMassDist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpredList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mdataSetResults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/smodels-graphs/notebooks-Devs/../smodels/theory/theoryPrediction.py\u001b[0m in \u001b[0;36m_getDataSetPredictions\u001b[0;34m(dataset, smsTopList, maxMassDist, marginalize, deltas_rel)\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0mtheoryPrediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0mtheoryPrediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtxnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtxnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m         \u001b[0mtheoryPrediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxsection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_evalConstraint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m         \u001b[0mtheoryPrediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconditions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_evalConditions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0mtheoryPrediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/smodels-graphs/notebooks-Devs/../smodels/theory/theoryPrediction.py\u001b[0m in \u001b[0;36m_evalConstraint\u001b[0;34m(cluster)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtxname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraint\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtxname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraint\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"not yet assigned\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtxname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m         \u001b[0mexprvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_evalExpression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mexprvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/smodels-graphs/notebooks-Devs/../smodels/theory/theoryPrediction.py\u001b[0m in \u001b[0;36m_evalExpression\u001b[0;34m(stringExpr, cluster)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0mweightsDict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"Cgtr\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcGtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cGtr\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcGtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cSim\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcSim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Csim\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcSim\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m     \u001b[0mexprvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalExpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweightsDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexprvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrossSection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXSectionList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexprvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'jet' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"\\n Theory Predictions and Constraints:\")\n",
    "rmax = 0.\n",
    "bestResult = None\n",
    "allPredictions = []\n",
    "for expResult in listOfExpRes:\n",
    "    predictions = theoryPredictionsFor(expResult, topDict, combinedResults=False, marginalize=False)\n",
    "    if not predictions:\n",
    "        continue  # Skip if there are no constraints from this result\n",
    "    print('\\n %s ' % expResult.globalInfo.id)\n",
    "    for theoryPrediction in predictions:\n",
    "        dataset = theoryPrediction.dataset\n",
    "        datasetID = theoryPrediction.dataId()\n",
    "        mass = theoryPrediction.mass\n",
    "        txnames = [str(txname) for txname in theoryPrediction.txnames]\n",
    "        PIDs = theoryPrediction.PIDs\n",
    "        print(\"------------------------\")\n",
    "        print(\"Dataset = \", datasetID)  # Analysis name\n",
    "        print(\"TxNames = \", txnames)\n",
    "        print(\"Prediction Mass = \", mass)  # Value for average cluster mass (average mass of the elements in cluster)\n",
    "        print(\"Prediction PIDs = \", PIDs)  # Value for average cluster mass (average mass of the elements in cluster)\n",
    "        print(\"Theory Prediction = \", theoryPrediction.xsection)  # Signal cross section\n",
    "        print(\"Condition Violation = \", theoryPrediction.conditions)  # Condition violation values\n",
    "\n",
    "        # Get the corresponding upper limit:\n",
    "        print(\"UL for theory prediction = \", theoryPrediction.upperLimit)\n",
    "\n",
    "        # Compute the r-value\n",
    "        r = theoryPrediction.getRValue()\n",
    "        print(\"r = %1.3E\" % r)\n",
    "        # Compute likelihoods for EM-type results:\n",
    "        if dataset.getType() == 'efficiencyMap':\n",
    "            theoryPrediction.computeStatistics()\n",
    "            print('L_BSM, L_SM, L_max = %1.3E, %1.3E, %1.3E' % (theoryPrediction.likelihood(),\n",
    "                  theoryPrediction.lsm(), theoryPrediction.lmax()))\n",
    "        if r > rmax:\n",
    "            rmax = r\n",
    "            bestResult = expResult.globalInfo.id\n",
    "        allPredictions.append(theoryPrediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
