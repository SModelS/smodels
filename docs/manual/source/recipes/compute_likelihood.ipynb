{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How To: Compute likelihood and chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the path to SModelS installation folder\n",
    "import sys; sys.path.append(\".\"); import smodels_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smodels.tools.simplifiedLikelihoods import LikelihoodComputer, Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to compute the likelihood and chi2 from the number of events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likelihood= 0.002043162995765441\n",
      "chi2= 7.753011557803882\n"
     ]
    }
   ],
   "source": [
    "# If the number of observed events, the number of expected background events,\n",
    "# its error and the number of signal events and its error are known, the likelihood\n",
    "# for the signal (assuming a truncated gaussian distribution for the background and signal uncertainties)\n",
    "# can be computed as:\n",
    "m=Data ( observed=5, backgrounds=4.2, covariance=0.71**2, third_moment=None, nsignal=.1 )\n",
    "comp=LikelihoodComputer ( m )\n",
    "print ('likelihood=',comp.likelihood(nsig = 10. ) )\n",
    "print ('chi2=',comp.chi2( nsig=10.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to compute the likelihood and chi2 from a theory prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In most cases one wants to compute the likelihood and chi2 for a given theory prediction computed by SModelS.\n",
    "# Below we generate theory predictions and compute the likelihood and chi2 values for them\n",
    "# First we import those parts of smodels that are needed for this exercise\n",
    "#(We will assume the input is a SLHA file. For LHE files, use the lheDecomposer instead)\n",
    "from smodels.share.models.mssm import BSMList\n",
    "from smodels.share.models.SMparticles import SMList\n",
    "from smodels.theory.model import Model\n",
    "from smodels.theory import decomposer\n",
    "from smodels.installation import installDirectory\n",
    "from smodels.tools.physicsUnits import fb, GeV\n",
    "from smodels.theory.theoryPrediction import theoryPredictionsFor\n",
    "from smodels.experiment.databaseObj import Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SLHA input file name\n",
    "filename=\"inputFiles/slha/gluino_squarks.slha\"\n",
    "model = Model(BSMparticles = BSMList, SMparticles = SMList)\n",
    "model.updateParticles(inputFile=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the database, do the decomposition and compute theory predictions:\n",
    "# (Look at the theory predictions HowTo to learn how to compute theory predictions)\n",
    "database = Database(\"official\")\n",
    "expResults = database.getExpResults(analysisIDs = [ \"ATLAS-SUSY-2018-31\"] )\n",
    "topList = decomposer.decompose(model, sigmacut = 0.03 * fb, doCompress=True, doInvisible=True,minmassgap = 5* GeV)\n",
    "allThPredictions = [theoryPredictionsFor(exp, topList) for exp in expResults]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experimental Result: ATLAS-SUSY-2018-31 (upperLimit-type)\n",
      "Theory prediction xsec =  2.87E-04 [pb]\n",
      "(likelihood not available)\n",
      "\n",
      "Experimental Result: ATLAS-SUSY-2018-31 (efficiencyMap-type)\n",
      "Theory prediction xsec =  2.05E-06 [pb]\n",
      "L_BSM, L_SM, L_max = 0.048346586018756285 0.055106218770918126 0.055106218770918126\n",
      "\n",
      "Experimental Result: ATLAS-SUSY-2018-31 (efficiencyMap-type)\n",
      "Theory prediction xsec =  4.14E-06 [pb]\n",
      "L_BSM, L_SM, L_max = 8.269995520939976e-22 9.72384439293845e-22 9.723844401058287e-22\n"
     ]
    }
   ],
   "source": [
    "# For each theory prediction, compute the corresponding likelihood and chi2 values\n",
    "# (This is only possible for efficiency map-type results):\n",
    "for i,thPreds in enumerate(allThPredictions):\n",
    "    if not thPreds: continue #skip results with no predictions\n",
    "    expID = expResults[i].globalInfo.id\n",
    "    dataType = expResults[i].getValuesFor('dataType')[0]    \n",
    "    for theoryPred in thPreds:\n",
    "        #Compute the likelihood and chi2:\n",
    "        theoryPred.computeStatistics()\n",
    "        print (\"\\nExperimental Result: %s (%s-type)\" %(expID,dataType)) #Result ID and type\n",
    "        print (\"Theory prediction xsec = \",theoryPred.xsection.value) #Signal xsection*efficiency*BR\n",
    "        if dataType == 'efficiencyMap':\n",
    "            theoryPred.computeStatistics()\n",
    "            print('L_BSM, L_SM, L_max =', theoryPred.likelihood, theoryPred.lsm, theoryPred.lmax )\n",
    "\n",
    "        else:\n",
    "            print (\"(likelihood not available)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
