{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import networkx as nx\n",
    "import time\n",
    "from smodels.theory.exceptions import SModelSTheoryError as SModelSError\n",
    "from smodels.tools.smodelsLogging import logger\n",
    "import matplotlib.pyplot as plt\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "from smodels.theory.element import Element\n",
    "from smodels.theory.topology import TopologyDict\n",
    "from smodels.theory.crossSection import XSection,XSectionInfo,XSectionList\n",
    "from smodels.particlesLoader import BSMList\n",
    "from smodels.share.models.SMparticles import SMList\n",
    "from smodels.theory.model import Model\n",
    "from smodels.tools.physicsUnits import fb, GeV\n",
    "from smodels.theory.tree import Tree,ParticleNode\n",
    "from smodels.theory.decomposer import cascadeDecay, addOneStepDecays\n",
    "import itertools\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose(model, sigmacut= 0*fb, doCompress=True, doInvisible=True,\n",
    "              minmassgap= 0*GeV):\n",
    "    \"\"\"\n",
    "    Perform decomposition using the information stored in model.\n",
    "    \n",
    "    :param sigmacut: minimum sigma*BR to be generated, by default sigmacut = 0.1 fb\n",
    "    :param doCompress: turn mass compression on/off\n",
    "    :param doInvisible: turn invisible compression on/off\n",
    "    :param minmassgap: maximum value (in GeV) for considering two R-odd particles\n",
    "                       degenerate (only revelant for doCompress=True )\n",
    "    :returns: list of topologies (TopologyList object)\n",
    "\n",
    "    \"\"\"\n",
    "    t1 = time.time()\n",
    "    \n",
    "    xSectionList = model.xsections    \n",
    "    pdgList = model.getValuesFor('pdg')\n",
    "\n",
    "    if doCompress and minmassgap/GeV < 0.:\n",
    "        logger.error(\"Asked for compression without specifying minmassgap. Please set minmassgap.\")        \n",
    "        raise SModelSError()\n",
    "\n",
    "    if isinstance(sigmacut,(float,int)):\n",
    "        sigmacut = float(sigmacut) * fb\n",
    "\n",
    "    xSectionList.removeLowerOrder()\n",
    "    # Order xsections by highest xsec value to improve performance\n",
    "    xSectionList.sort()\n",
    "\n",
    "    # Generate all primary nodes (e.g. PV > X+Y)\n",
    "    # and assign the nodeWeight as the maximum cross-section\n",
    "    productionTrees = []\n",
    "    for pid in xSectionList.getPIDpairs():\n",
    "        weight = xSectionList.getXsecsFor(pid)\n",
    "        if weight < sigmacut:\n",
    "            continue\n",
    "        pv = ParticleNode(model.getParticlesWith(label='PV')[0],0,nodeWeight=weight)\n",
    "        pv.xsection = xSectionList.getXsecsFor(pid)\n",
    "        primaryMothers = [ParticleNode(model.getParticlesWith(pdg=pdg)[0],i+1) for i,pdg in enumerate(pid)]\n",
    "        productionTrees.append(Tree({pv : primaryMothers}))\n",
    "\n",
    "    # Sort production trees\n",
    "    productionTrees = sorted(productionTrees, key = lambda t: t.getTreeWeight().getMaxXsec(), reverse=True)\n",
    "    \n",
    "    \n",
    "    print('%i production trees' %len(productionTrees))\n",
    "#     return productionTrees\n",
    "    # For each production tree, produce all allowed cascade decays (above sigmacut):\n",
    "    allTrees = []\n",
    "    for tree in productionTrees:\n",
    "#         print('len=',len(allTrees))\n",
    "        allTrees += cascadeDecay(tree,sigmacut=sigmacut)\n",
    "\n",
    "    print('%i decayed trees' %len(allTrees))\n",
    "#     return allTrees\n",
    "\n",
    "    # Create elements for each tree and combine equal elements\n",
    "    smsTopDict = TopologyDict()\n",
    "\n",
    "    allEls = []\n",
    "    for tree in allTrees:\n",
    "        newElement = Element(tree)\n",
    "        newElement.weight = tree.getTreeWeight()\n",
    "        \n",
    "        \n",
    "#         if newElement.tree.canonName == 11101010011011010000:\n",
    "#             print('el created as:')\n",
    "#             for d in newElement.tree.successors(newElement.tree.getTreeRoot()):\n",
    "#                 print(d,d.canonName)\n",
    "        \n",
    "        \n",
    "#         allEls.append(newElement)\n",
    "        smsTopDict.addElement(newElement)                                                 \n",
    "                                                    \n",
    "#     smsTopDict.compressElements(doCompress, doInvisible, minmassgap)\n",
    "#     smsTopDict._setElementIds()    \n",
    "    print('total number of unique elements = %i' %len(smsTopDict.getElements()))\n",
    "    print(\"decomposer done in %.2f s.\" % (time.time() -t1 ) )\n",
    "    \n",
    "#     return allEls\n",
    "    return smsTopDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "slhafile = '../inputFiles/slha/lightEWinos.slha'\n",
    "# slhafile = '../inputFiles/slha/simplyGluino.slha'\n",
    "model = Model(BSMparticles=BSMList, SMparticles=SMList)\n",
    "model.updateParticles(inputFile=slhafile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 production trees\n",
      "219 decayed trees\n",
      "total number of unique elements = 120\n",
      "decomposer done in 0.94 s.\n",
      "(expected = 14647 trees)\n",
      "(expected = 5435 unique elements)\n"
     ]
    }
   ],
   "source": [
    "sigmacut = 10*fb\n",
    "# sigmacut = 0.1*fb\n",
    "topDict = decompose(model, sigmacut= sigmacut)\n",
    "nTotal = 14647\n",
    "nUnique = 5435 # uncompressed\n",
    "print('(expected = %i trees)' %nTotal)\n",
    "print('(expected = %i unique elements)' %nUnique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110110101000 2 [[], [['q', 'q']]]\n",
      "111010100110101000 59 [[['e-', 'nu']], [['nu', 'e+']]]\n",
      "11101010011011010000 1 [[['b', 'b']], [['g'], ['Z']]]\n",
      "111010100110101101010000 7 [[['b', 'b']], [['t-', 'b'], ['q', 'q']]]\n",
      "11101010011011011010100000 4 [[['b', 'b']], [['g'], ['W-'], ['q', 'q']]]\n",
      "11101101000110101101010000 4 [[['g'], ['Z']], [['t-', 'b'], ['q', 'q']]]\n",
      "111010110101000110101101010000 43 [[['t-/b/b', 'b'], ['q', 'q']], [['t-/b/b', 'b'], ['q', 'q']]]\n"
     ]
    }
   ],
   "source": [
    "for c in sorted(topDict.keys()):\n",
    "#     print(c,len(topDict[c]),topDict[c][0])\n",
    "    print(c,len(topDict[c]),topDict[c][0].tree.treeToBrackets()[0])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elList = topDict[11101010011011010000]\n",
    "for el in elList:\n",
    "#     if el.getCanonName() != 11101010011011010000:\n",
    "#         continue\n",
    "    el.sort()\n",
    "    print('el == el',el == elList[0])\n",
    "    print(el)\n",
    "    for node in el.tree.nodes():\n",
    "        print('  ',node,node.canonName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %lprun -f addOneStepDecays decompose(model, sigmacut= sigmacut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ela = topDict[11101010011011010000][0]\n",
    "elb = topDict[11101010011011010000][1]\n",
    "# ela.sort()\n",
    "# elb.sort()\n",
    "print(ela)\n",
    "print(elb)\n",
    "print(ela == elb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in ela.tree.nodes():\n",
    "    print(node,node.canonName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in elb.tree.nodes():\n",
    "    print(node,node.canonName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elb.tree.sort()\n",
    "for node in elb.tree.nodes():\n",
    "    print(node,node.canonName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "massA = list(zip(ela.tree.nodes(),ela.mass))\n",
    "massB = list(zip(elb.tree.nodes(),elb.mass))\n",
    "\n",
    "for im,m in enumerate(massA):\n",
    "    print(m[0],massB[im][0])\n",
    "    print('   mA=',m[1],'mB=',massB[im][1],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ela.drawTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elb.drawTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
