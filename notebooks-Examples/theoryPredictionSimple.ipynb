{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "sys.path.append('../')\n",
    "from smodels.tools import runtime\n",
    "# Define your model (list of BSM particles)\n",
    "runtime.modelFile = 'smodels.share.models.mssm'\n",
    "# runtime.modelFile = 'mssmQNumbers.slha'\n",
    "\n",
    "from smodels.theory import decomposer\n",
    "from smodels.tools.physicsUnits import fb, GeV, TeV\n",
    "from smodels.theory.theoryPrediction import theoryPredictionsFor\n",
    "from smodels.experiment.databaseObj import Database\n",
    "from smodels.tools.theoryPredictionsCombiner import TheoryPredictionsCombiner\n",
    "from smodels.tools.smodelsLogging import setLogLevel\n",
    "from smodels.particlesLoader import BSMList\n",
    "from smodels.share.models.SMparticles import SMList\n",
    "from smodels.theory.model import Model\n",
    "setLogLevel(\"error\")\n",
    "\n",
    "# Set the path to the database\n",
    "database = Database(os.path.expanduser(\"../test/database\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "slhafile = '../inputFiles/slha/simplyGluino.slha'\n",
    "model = Model(BSMparticles=BSMList, SMparticles=SMList)\n",
    "model.updateParticles(inputFile=slhafile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set main options for decomposition\n",
    "sigmacut = 0.005*fb\n",
    "mingap = 5.*GeV\n",
    "\n",
    "# Decompose model\n",
    "topDict = decomposer.decompose(model, sigmacut,\n",
    "                               massCompress=True, invisibleCompress=True,\n",
    "                               minmassgap=mingap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the experimental results to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfExpRes = database.getExpResults(analysisIDs=['ATLAS-SUSY-2013-02','CMS-SUS-13-012'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the theory predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Theory Predictions and Constraints:\n",
      "\n",
      " ATLAS-SUSY-2013-02 \n",
      "------------------------\n",
      "Dataset =  None\n",
      "TxNames =  ['T1']\n",
      "Theory Prediction =  5.72E-01 [pb]\n",
      "Condition Violation =  None\n",
      "UL for theory prediction =  3.81E+01 [fb]\n",
      "r = 1.500E+01\n",
      "\n",
      " CMS-SUS-13-012 \n",
      "------------------------\n",
      "Dataset =  6NJet8_1000HT1250_450MHTinf\n",
      "TxNames =  ['T1']\n",
      "Theory Prediction =  1.72E-03 [pb]\n",
      "Condition Violation =  None\n",
      "UL for theory prediction =  3.86E-01 [fb]\n",
      "r = 4.450E+00\n",
      "L_BSM, L_SM, L_max = 1.267E-11, 4.876E-02, 7.085E-02\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Theory Predictions and Constraints:\")\n",
    "rmax = 0.\n",
    "bestResult = None\n",
    "allPredictions = []\n",
    "for expResult in listOfExpRes:\n",
    "    predictions = theoryPredictionsFor(expResult, topDict, combinedResults=False, marginalize=False)\n",
    "    if not predictions:\n",
    "        continue  # Skip if there are no constraints from this result\n",
    "    print('\\n %s ' % expResult.globalInfo.id)\n",
    "    for theoryPrediction in predictions:\n",
    "        dataset = theoryPrediction.dataset\n",
    "        datasetID = theoryPrediction.dataId()\n",
    "        txnames = [str(txname) for txname in theoryPrediction.txnames]\n",
    "        print(\"------------------------\")\n",
    "        print(\"Dataset = \", datasetID)  # Analysis name\n",
    "        print(\"TxNames = \", txnames)\n",
    "        print(\"Theory Prediction = \", theoryPrediction.xsection)  # Signal cross section\n",
    "        print(\"Condition Violation = \", theoryPrediction.conditions)  # Condition violation values\n",
    "\n",
    "        # Get the corresponding upper limit:\n",
    "        print(\"UL for theory prediction = \", theoryPrediction.upperLimit)\n",
    "\n",
    "        # Compute the r-value\n",
    "        r = theoryPrediction.getRValue()\n",
    "        print(\"r = %1.3E\" % r)\n",
    "        # Compute likelihoods for EM-type results:\n",
    "        if dataset.getType() == 'efficiencyMap':\n",
    "            theoryPrediction.computeStatistics()\n",
    "            print('L_BSM, L_SM, L_max = %1.3E, %1.3E, %1.3E' % (theoryPrediction.likelihood(),\n",
    "                  theoryPrediction.lsm(), theoryPrediction.lmax()))\n",
    "        if r > rmax:\n",
    "            rmax = r\n",
    "            bestResult = expResult.globalInfo.id\n",
    "        allPredictions.append(theoryPrediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
